**重点参考：https://github.com/facebookresearch/maskrcnn-benchmark**



+ 如何在maskrcnn的关键点检测方法中引入hrnet中的heatmap呢？结合hrnet中的lib/dataset/中的coco.py和JointsDataset.py，重写maskrcnn-benchmark中的data/datasets/中的coco.py。

  + 注意，hrnet中dataloader的dataset类的get item是加载人的实例，而maskrcnn训练时get item加载的是图片。
  + 要注意keypoint_head的输出要从[N, K, 3]变换成[N, K, 64, 48]，并重新计算损失函数。原损失函数在modeling/roi_heads/keypoint_head/loss.py中。

+ 要适配HR_MaskRCNN关键点检测任务，需要修改configs中的yaml配置文件

  



### roi_head

```python
# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
import torch

from .box_head.box_head import build_roi_box_head
from .mask_head.mask_head import build_roi_mask_head
from .keypoint_head.keypoint_head import build_roi_keypoint_head


class CombinedROIHeads(torch.nn.ModuleDict):
    """
    Combines a set of individual heads (for box prediction or masks) into a single head.
    """

    def __init__(self, cfg, heads):
        super(CombinedROIHeads, self).__init__(heads)
        self.cfg = cfg.clone()
        if cfg.MODEL.MASK_ON and cfg.MODEL.ROI_MASK_HEAD.SHARE_BOX_FEATURE_EXTRACTOR:
            self.mask.feature_extractor = self.box.feature_extractor
        if cfg.MODEL.KEYPOINT_ON and cfg.MODEL.ROI_KEYPOINT_HEAD.SHARE_BOX_FEATURE_EXTRACTOR:
            self.keypoint.feature_extractor = self.box.feature_extractor

    def forward(self, features, proposals, targets=None):
        losses = {}
        # TODO rename x to roi_box_features, if it doesn't increase memory consumption
        x, detections, loss_box = self.box(features, proposals, targets)
        losses.update(loss_box)
        if self.cfg.MODEL.MASK_ON:
            mask_features = features
            # optimization: during training, if we share the feature extractor between
            # the box and the mask heads, then we can reuse the features already computed
            if (
                self.training
                and self.cfg.MODEL.ROI_MASK_HEAD.SHARE_BOX_FEATURE_EXTRACTOR
            ):
                mask_features = x
            # During training, self.box() will return the unaltered proposals as "detections"
            # this makes the API consistent during training and testing
            x, detections, loss_mask = self.mask(mask_features, detections, targets)
            losses.update(loss_mask)

        if self.cfg.MODEL.KEYPOINT_ON:
            keypoint_features = features
            # optimization: during training, if we share the feature extractor between
            # the box and the mask heads, then we can reuse the features already computed
            if (
                self.training
                and self.cfg.MODEL.ROI_KEYPOINT_HEAD.SHARE_BOX_FEATURE_EXTRACTOR
            ):
                keypoint_features = x
            # During training, self.box() will return the unaltered proposals as "detections"
            # this makes the API consistent during training and testing
            x, detections, loss_keypoint = self.keypoint(keypoint_features, detections, targets)
            losses.update(loss_keypoint)
        return x, detections, losses


def build_roi_heads(cfg, in_channels):
    # individually create the heads, that will be combined together afterwards
    roi_heads = []
    if cfg.MODEL.RETINANET_ON:
        return []

    if not cfg.MODEL.RPN_ONLY:
        roi_heads.append(("box", build_roi_box_head(cfg, in_channels)))
    if cfg.MODEL.MASK_ON:
        roi_heads.append(("mask", build_roi_mask_head(cfg, in_channels)))
    if cfg.MODEL.KEYPOINT_ON:
        roi_heads.append(("keypoint", build_roi_keypoint_head(cfg, in_channels)))

    # combine individual heads in a single module
    if roi_heads:
        roi_heads = CombinedROIHeads(cfg, roi_heads)

    return roi_heads

```



### keypoint_head

+ [maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py) (也可参考[facebookresearch/detectron2/modeling/roi_heads/keypoint_head.py](https://github.com/facebookresearch/detectron2))。

```python
import torch

from .roi_keypoint_feature_extractors import make_roi_keypoint_feature_extractor
from .roi_keypoint_predictors import make_roi_keypoint_predictor
from .inference import make_roi_keypoint_post_processor
from .loss import make_roi_keypoint_loss_evaluator


class ROIKeypointHead(torch.nn.Module):
    def __init__(self, cfg, in_channels):
        super(ROIKeypointHead, self).__init__()
        self.cfg = cfg.clone()
        self.feature_extractor = make_roi_keypoint_feature_extractor(cfg, in_channels)
        self.predictor = make_roi_keypoint_predictor(
            cfg, self.feature_extractor.out_channels)
        self.post_processor = make_roi_keypoint_post_processor(cfg)
        self.loss_evaluator = make_roi_keypoint_loss_evaluator(cfg)

    def forward(self, features, proposals, targets=None):
        """
        Arguments:
            features (list[Tensor]): feature-maps from possibly several levels
            proposals (list[BoxList]): proposal boxes
            targets (list[BoxList], optional): the ground-truth targets.

        Returns:
            x (Tensor): the result of the feature extractor
            proposals (list[BoxList]): during training, the original proposals
                are returned. During testing, the predicted boxlists are returned
                with the `mask` field set
            losses (dict[Tensor]): During training, returns the losses for the
                head. During testing, returns an empty dict.
        """
        if self.training:
            with torch.no_grad():
                proposals = self.loss_evaluator.subsample(proposals, targets)

        x = self.feature_extractor(features, proposals)
        kp_logits = self.predictor(x)

        if not self.training:
            result = self.post_processor(kp_logits, proposals)
            return x, result, {}

        loss_kp = self.loss_evaluator(proposals, kp_logits)

        return x, proposals, dict(loss_kp=loss_kp)


def build_roi_keypoint_head(cfg, in_channels):
    return ROIKeypointHead(cfg, in_channels)

```



+ 修改`maskrcnn_benchmark/modeling/detector/generalized_rcnn.py`

```python
# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
"""
Implements the Generalized R-CNN framework
"""

import torch
from torch import nn

from maskrcnn_benchmark.structures.image_list import to_image_list

from ..backbone import build_backbone
from ..rpn.rpn import build_rpn
from ..roi_heads.roi_heads import build_roi_heads


class GeneralizedRCNN(nn.Module):
    """
    Main class for Generalized R-CNN. Currently supports boxes and masks.
    It consists of three main parts:
    - backbone
    = rpn
    - heads: takes the features + the proposals from the RPN and computes
        detections / masks from it.
    """

    def __init__(self, cfg):
        super(GeneralizedRCNN, self).__init__()

        self.backbone = build_backbone(cfg)
        self.rpn = build_rpn(cfg)
        self.roi_heads = build_roi_heads(cfg)

    def forward(self, images, targets=None):
        """
        Arguments:
            images (list[Tensor] or ImageList): images to be processed
            targets (list[BoxList]): ground-truth boxes present in the image (optional)

        Returns:
            result (list[BoxList] or dict[Tensor]): the output from the model.
                During training, it returns a dict[Tensor] which contains the losses.
                During testing, it returns list[BoxList] contains additional fields
                like `scores`, `labels` and `mask` (for Mask R-CNN models).

        """
        if self.training and targets is None:
            raise ValueError("In training mode, targets should be passed")
        images = to_image_list(images)
        features = self.backbone(images.tensors)
        proposals, proposal_losses = self.rpn(images, features, targets)
        if self.roi_heads:
            x, result, detector_losses = self.roi_heads(features, proposals, targets)
        else:
            # RPN-only models don't have roi_heads
            x = features
            result = proposals
            detector_losses = {}

        if self.training:
            losses = {}
            losses.update(detector_losses)
            losses.update(proposal_losses)
            return losses

        return result

```



### backbone

创建骨干网络：`maskrcnn_benchmark/modeling/backbone/backbone.py`；

```python
def build_backbone(cfg):
    assert cfg.MODEL.BACKBONE.CONV_BODY in registry.BACKBONES, \
        "cfg.MODEL.BACKBONE.CONV_BODY: {} are not registered in registry".format(
            cfg.MODEL.BACKBONE.CONV_BODY
        )
    return registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY](cfg)
```



HRNET-HR(我觉得应该叫HRNET-FPN)骨干网络结构：`maskrcnn_benchmark/modeling/backbone/backbone.py`；

```python
@registry.BACKBONES.register('HRNET-HR')
def build_hrnet_hr_backbone(cfg):
    body = hrnet.HRNet(cfg)
    neck = hrfpn.HRFPN(cfg)
    model = nn.Sequential(OrderedDict([('body', body), ('neck', neck)]))
    return model
```



网络结构HRFPN：`maskrcnn_benchmark/modeling/backbone/hrfpn.py`；

```python
class HRFPN(nn.Module):

    def __init__(self, cfg):
        super(HRFPN, self).__init__()

        config = cfg.MODEL.NECK
```



```yaml
MODEL:  
  NECK:
    IN_CHANNELS:
      - 18
      - 36
      - 72
      - 144
    OUT_CHANNELS: 256
    POOLING: "AVG"
```





### rpn





### head









+ 关注一下[vision/torchvision/models/detection/roi_heads.py](https://github.com/pytorch/vision/blob/f7fae490980885e426fef01bb214025b9eddb832/torchvision/models/detection/roi_heads.py)中的select_training_samples中的regression_targets；（讲gt_bbox加入到proposals？为什么呢？让网络更好训练吗？刚开始的时候，proposals可能不准，不合适的框用来做关键点检测可能没啥用）







## Debug

#### 数据集错误

```shell
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py", line 156, in get
    attrs = DatasetCatalog.DATASETS[name]
KeyError: 'keypoints_coco_2017_train'
```

修改配置文件：maskrcnn-benchmark/configs/e2e_keypoint_rcnn_R_50_FPN_1x_train2017.yaml

```yaml
DATASETS:
  TRAIN: ("keypoints_coco_2017_train", "keypoints_coco_2017_val",)
  TEST: ("keypoints_coco_2017_val",)
```

修改paths：maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py

```python
        "keypoints_coco_2017_train": {
            "img_dir": "coco/images/train2017",
            "ann_file": "coco/annotations/person_keypoints_train2017.json",
        },
        "keypoints_coco_2017_val": {
            "img_dir": "coco/images/val2017",
            "ann_file": "coco/annotations/person_keypoints_val2017.json"
        },
```

#### 显存不足

```shell
RuntimeError: CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 7.80 GiB total capacity; 6.58 GiB already allocated; 90.31 MiB free; 7.01 GiB reserved in total by PyTorch)
```

默认是16：/maskrcnn_benchmark/config/defaults.py

```python
# Number of images per batch
# This is global, so if we have 8 GPUs and IMS_PER_BATCH = 16, each GPU will
# see 2 images per batch
_C.SOLVER.IMS_PER_BATCH = 16
```

修改配置文件：maskrcnn-benchmark/configs/e2e_keypoint_rcnn_R_50_FPN_1x_train2017.yaml

```yaml
SOLVER:
  IMS_PER_BATCH: 2
```



#### device-side assert triggered

```shell
RuntimeError: copy_if failed to synchronize: cudaErrorAssert: device-side assert triggered
```

参考：https://github.com/facebookresearch/maskrcnn-benchmark/issues/733

```txt
Jayis commented on 30 May 2019
same error

if the problem happened in training, smaller learning rate helps
but I've also encountered this error while testing once...
while testing, that's not possible to solve it by using smaller learning rate, right?

I've tried to debug, but I can't even access the "boxlist".
Runtime error happened when I try to print the "boxlist".

I really want to know if anybody had another solution rather than just "using smaller learning rate"...
```

把学习率调小：

```yaml
SOLVER:
  BASE_LR: 0.0005
  WEIGHT_DECAY: 0.00001
```

