**重点参考：https://github.com/facebookresearch/maskrcnn-benchmark**

+ 先在maskrcnn-benchmark的backbone中添加hrnet（Done）

+ 如何在maskrcnn的关键点检测方法中引入hrnet中的heatmap呢？结合hrnet中的lib/dataset/中的coco.py和JointsDataset.py，重写maskrcnn-benchmark中的data/datasets/中的coco.py。

  + 注意，hrnet中dataloader的dataset类的get item是加载人的实例，而maskrcnn训练时get item加载的是图片。
  + 要注意keypoint_head的输出要从[N, K, 3]变换成[N, K, 64, 48]，并重新计算损失函数。原损失函数在modeling/roi_heads/keypoint_head/loss.py中。

+ 要适配HR_MaskRCNN关键点检测任务，需要修改configs中的yaml配置文件

  

+ 后面持续将DARK、UDP、AID的思想引入进来。**当前先完成heatmap的替换**。

### roi_head

```python
# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
import torch

from .box_head.box_head import build_roi_box_head
from .mask_head.mask_head import build_roi_mask_head
from .keypoint_head.keypoint_head import build_roi_keypoint_head


class CombinedROIHeads(torch.nn.ModuleDict):
    """
    Combines a set of individual heads (for box prediction or masks) into a single head.
    """

    def __init__(self, cfg, heads):
        super(CombinedROIHeads, self).__init__(heads)
        self.cfg = cfg.clone()
        if cfg.MODEL.MASK_ON and cfg.MODEL.ROI_MASK_HEAD.SHARE_BOX_FEATURE_EXTRACTOR:
            self.mask.feature_extractor = self.box.feature_extractor
        if cfg.MODEL.KEYPOINT_ON and cfg.MODEL.ROI_KEYPOINT_HEAD.SHARE_BOX_FEATURE_EXTRACTOR:
            self.keypoint.feature_extractor = self.box.feature_extractor

    def forward(self, features, proposals, targets=None):
        losses = {}
        # TODO rename x to roi_box_features, if it doesn't increase memory consumption
        x, detections, loss_box = self.box(features, proposals, targets)
        losses.update(loss_box)
        if self.cfg.MODEL.MASK_ON:
            mask_features = features
            # optimization: during training, if we share the feature extractor between
            # the box and the mask heads, then we can reuse the features already computed
            if (
                self.training
                and self.cfg.MODEL.ROI_MASK_HEAD.SHARE_BOX_FEATURE_EXTRACTOR
            ):
                mask_features = x
            # During training, self.box() will return the unaltered proposals as "detections"
            # this makes the API consistent during training and testing
            x, detections, loss_mask = self.mask(mask_features, detections, targets)
            losses.update(loss_mask)

        if self.cfg.MODEL.KEYPOINT_ON:
            keypoint_features = features
            # optimization: during training, if we share the feature extractor between
            # the box and the mask heads, then we can reuse the features already computed
            if (
                self.training
                and self.cfg.MODEL.ROI_KEYPOINT_HEAD.SHARE_BOX_FEATURE_EXTRACTOR
            ):
                keypoint_features = x
            # During training, self.box() will return the unaltered proposals as "detections"
            # this makes the API consistent during training and testing
            x, detections, loss_keypoint = self.keypoint(keypoint_features, detections, targets)
            losses.update(loss_keypoint)
        return x, detections, losses


def build_roi_heads(cfg, in_channels):
    # individually create the heads, that will be combined together afterwards
    roi_heads = []
    if cfg.MODEL.RETINANET_ON:
        return []

    if not cfg.MODEL.RPN_ONLY:
        roi_heads.append(("box", build_roi_box_head(cfg, in_channels)))
    if cfg.MODEL.MASK_ON:
        roi_heads.append(("mask", build_roi_mask_head(cfg, in_channels)))
    if cfg.MODEL.KEYPOINT_ON:
        roi_heads.append(("keypoint", build_roi_keypoint_head(cfg, in_channels)))

    # combine individual heads in a single module
    if roi_heads:
        roi_heads = CombinedROIHeads(cfg, roi_heads)

    return roi_heads

```



### keypoint_head

+ [maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py](https://github.com/facebookresearch/maskrcnn-benchmark/blob/master/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py) (也可参考[facebookresearch/detectron2/modeling/roi_heads/keypoint_head.py](https://github.com/facebookresearch/detectron2))。

```python
import torch

from .roi_keypoint_feature_extractors import make_roi_keypoint_feature_extractor
from .roi_keypoint_predictors import make_roi_keypoint_predictor
from .inference import make_roi_keypoint_post_processor
from .loss import make_roi_keypoint_loss_evaluator


class ROIKeypointHead(torch.nn.Module):
    def __init__(self, cfg, in_channels):
        super(ROIKeypointHead, self).__init__()
        self.cfg = cfg.clone()
        self.feature_extractor = make_roi_keypoint_feature_extractor(cfg, in_channels)
        self.predictor = make_roi_keypoint_predictor(
            cfg, self.feature_extractor.out_channels)
        self.post_processor = make_roi_keypoint_post_processor(cfg)
        self.loss_evaluator = make_roi_keypoint_loss_evaluator(cfg)

    def forward(self, features, proposals, targets=None):
        """
        Arguments:
            features (list[Tensor]): feature-maps from possibly several levels
            proposals (list[BoxList]): proposal boxes
            targets (list[BoxList], optional): the ground-truth targets.

        Returns:
            x (Tensor): the result of the feature extractor
            proposals (list[BoxList]): during training, the original proposals
                are returned. During testing, the predicted boxlists are returned
                with the `mask` field set
            losses (dict[Tensor]): During training, returns the losses for the
                head. During testing, returns an empty dict.
        """
        if self.training:
            with torch.no_grad():
                proposals = self.loss_evaluator.subsample(proposals, targets)

        x = self.feature_extractor(features, proposals)
        kp_logits = self.predictor(x)

        if not self.training:
            result = self.post_processor(kp_logits, proposals)
            return x, result, {}

        loss_kp = self.loss_evaluator(proposals, kp_logits)

        return x, proposals, dict(loss_kp=loss_kp)


def build_roi_keypoint_head(cfg, in_channels):
    return ROIKeypointHead(cfg, in_channels)

```



+ 修改`maskrcnn_benchmark/modeling/detector/generalized_rcnn.py`

```python
# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
"""
Implements the Generalized R-CNN framework
"""

import torch
from torch import nn

from maskrcnn_benchmark.structures.image_list import to_image_list

from ..backbone import build_backbone
from ..rpn.rpn import build_rpn
from ..roi_heads.roi_heads import build_roi_heads


class GeneralizedRCNN(nn.Module):
    """
    Main class for Generalized R-CNN. Currently supports boxes and masks.
    It consists of three main parts:
    - backbone
    = rpn
    - heads: takes the features + the proposals from the RPN and computes
        detections / masks from it.
    """

    def __init__(self, cfg):
        super(GeneralizedRCNN, self).__init__()

        self.backbone = build_backbone(cfg)
        self.rpn = build_rpn(cfg)
        self.roi_heads = build_roi_heads(cfg)

    def forward(self, images, targets=None):
        """
        Arguments:
            images (list[Tensor] or ImageList): images to be processed
            targets (list[BoxList]): ground-truth boxes present in the image (optional)

        Returns:
            result (list[BoxList] or dict[Tensor]): the output from the model.
                During training, it returns a dict[Tensor] which contains the losses.
                During testing, it returns list[BoxList] contains additional fields
                like `scores`, `labels` and `mask` (for Mask R-CNN models).

        """
        if self.training and targets is None:
            raise ValueError("In training mode, targets should be passed")
        images = to_image_list(images)
        features = self.backbone(images.tensors)
        proposals, proposal_losses = self.rpn(images, features, targets)
        if self.roi_heads:
            x, result, detector_losses = self.roi_heads(features, proposals, targets)
        else:
            # RPN-only models don't have roi_heads
            x = features
            result = proposals
            detector_losses = {}

        if self.training:
            losses = {}
            losses.update(detector_losses)
            losses.update(proposal_losses)
            return losses

        return result

```



### backbone

创建骨干网络：`maskrcnn_benchmark/modeling/backbone/backbone.py`；

```python
def build_backbone(cfg):
    assert cfg.MODEL.BACKBONE.CONV_BODY in registry.BACKBONES, \
        "cfg.MODEL.BACKBONE.CONV_BODY: {} are not registered in registry".format(
            cfg.MODEL.BACKBONE.CONV_BODY
        )
    return registry.BACKBONES[cfg.MODEL.BACKBONE.CONV_BODY](cfg)
```



HRNET-HR(我觉得应该叫HRNET-FPN)骨干网络结构：`maskrcnn_benchmark/modeling/backbone/backbone.py`；

```python
@registry.BACKBONES.register('HRNET-HR')
def build_hrnet_hr_backbone(cfg):
    body = hrnet.HRNet(cfg)
    neck = hrfpn.HRFPN(cfg)
    model = nn.Sequential(OrderedDict([('body', body), ('neck', neck)]))
    return model
```



网络结构HRFPN：`maskrcnn_benchmark/modeling/backbone/hrfpn.py`；

```python
class HRFPN(nn.Module):

    def __init__(self, cfg):
        super(HRFPN, self).__init__()

        config = cfg.MODEL.NECK
```



```yaml
MODEL:  
  NECK:
    IN_CHANNELS:
      - 18
      - 36
      - 72
      - 144
    OUT_CHANNELS: 256
    POOLING: "AVG"
```





### rpn





### head









+ 关注一下[vision/torchvision/models/detection/roi_heads.py](https://github.com/pytorch/vision/blob/f7fae490980885e426fef01bb214025b9eddb832/torchvision/models/detection/roi_heads.py)中的select_training_samples中的regression_targets；（讲gt_bbox加入到proposals？为什么呢？让网络更好训练吗？刚开始的时候，proposals可能不准，不合适的框用来做关键点检测可能没啥用）







## Debug

#### 数据集错误

```shell
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py", line 156, in get
    attrs = DatasetCatalog.DATASETS[name]
KeyError: 'keypoints_coco_2017_train'
```

修改配置文件：maskrcnn-benchmark/configs/e2e_keypoint_rcnn_R_50_FPN_1x_train2017.yaml

```yaml
DATASETS:
  TRAIN: ("keypoints_coco_2017_train", "keypoints_coco_2017_val",)
  TEST: ("keypoints_coco_2017_val",)
```

修改paths：maskrcnn-benchmark/maskrcnn_benchmark/config/paths_catalog.py

```python
        "keypoints_coco_2017_train": {
            "img_dir": "coco/images/train2017",
            "ann_file": "coco/annotations/person_keypoints_train2017.json",
        },
        "keypoints_coco_2017_val": {
            "img_dir": "coco/images/val2017",
            "ann_file": "coco/annotations/person_keypoints_val2017.json"
        },
```

#### 显存不足

```shell
RuntimeError: CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 7.80 GiB total capacity; 6.58 GiB already allocated; 90.31 MiB free; 7.01 GiB reserved in total by PyTorch)
```

默认是16：/maskrcnn_benchmark/config/defaults.py

```python
# Number of images per batch
# This is global, so if we have 8 GPUs and IMS_PER_BATCH = 16, each GPU will
# see 2 images per batch
_C.SOLVER.IMS_PER_BATCH = 16
```

修改配置文件：maskrcnn-benchmark/configs/e2e_keypoint_rcnn_R_50_FPN_1x_train2017.yaml

```yaml
SOLVER:
  IMS_PER_BATCH: 2
```



#### "index out of bounds"` failed

#### device-side assert triggered

```shell
RuntimeError: copy_if failed to synchronize: cudaErrorAssert: device-side assert triggered
```

参考：https://github.com/facebookresearch/maskrcnn-benchmark/issues/733

```txt
Jayis commented on 30 May 2019
same error

if the problem happened in training, smaller learning rate helps
but I've also encountered this error while testing once...
while testing, that's not possible to solve it by using smaller learning rate, right?

I've tried to debug, but I can't even access the "boxlist".
Runtime error happened when I try to print the "boxlist".

I really want to know if anybody had another solution rather than just "using smaller learning rate"...
```

把学习率调小：

```yaml
SOLVER:
  BASE_LR: 0.0005
  WEIGHT_DECAY: 0.00001
```



#### 'Non-existent config key: MODEL.BACKBONE.OUT_CHANNELS'

```shell
  File "tools/train_net.py", line 172, in main
    cfg.merge_from_file(args.config_file)
```


在默认的config文件中添加MODEL.BACKBONE.OUT_CHANNELS：/maskrcnn_benchmark/config/defaults.py

```yaml
_C.MODEL.BACKBONE.OUT_CHANNELS = 256 * 4
```



#### 'Sequential' object has no attribute 'out_channels'

```shell
  File "/home/wenxue/projects/maskrcnn-benchmark/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py", line 30, in __init__
    self.rpn = build_rpn(cfg, self.backbone.out_channels)  ##self.rpn为build_rpn中的RPNModule(cfg, in_channels)

```

对比maskrcnn-benchmark与HRNet_MaskRCNN中的/maskrcnn_benchmark/modeling/rpn/rpn.py，前者带参数in_channels，后者不带；后者在`class RPNModule(torch.nn.Module)`中多了一行代码`in_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS`；因此我的修改方案是在/maskrcnn_benchmark/modeling/backbone/backbone.py中对hrnet进行修改，添加out_channels属性：

```python
@registry.BACKBONES.register("HRNET")
def build_hrnet_backbone(cfg):
    body = hrnet.HRNet(cfg)
    model = nn.Sequential(OrderedDict([("body", body)]))
    model.out_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS
    return model


@registry.BACKBONES.register('HRNET-FPN')  ##我觉得应该叫HRNET-FPN
def build_hrnet_fpn_backbone(cfg):
    body = hrnet.HRNet(cfg)
    neck = hrfpn.HRFPN(cfg)
    model = nn.Sequential(OrderedDict([('body', body), ('neck', neck)]))
    model.out_channels = cfg.MODEL.BACKBONE.OUT_CHANNELS
    return model
```



根据HRNet_MaskRCNN进行修改：/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py

注意在maskrcnn-benchmark中的/maskrcnn_benchmark/modeling/backbone/backbone.py中，resnet等模型都有out_channels这个属性；

```python
@registry.BACKBONES.register("R-50-C4")
@registry.BACKBONES.register("R-50-C5")
@registry.BACKBONES.register("R-101-C4")
@registry.BACKBONES.register("R-101-C5")
def build_resnet_backbone(cfg):
    body = resnet.ResNet(cfg)
    model = nn.Sequential(OrderedDict([("body", body)]))
    model.out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
    return model


@registry.BACKBONES.register("R-50-FPN")
@registry.BACKBONES.register("R-101-FPN")
@registry.BACKBONES.register("R-152-FPN")
def build_resnet_fpn_backbone(cfg):
    body = resnet.ResNet(cfg)
    in_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
    out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
    fpn = fpn_module.FPN(
        in_channels_list=[
            in_channels_stage2,
            in_channels_stage2 * 2,
            in_channels_stage2 * 4,
            in_channels_stage2 * 8,
        ],
        out_channels=out_channels,
        conv_block=conv_with_kaiming_uniform(
            cfg.MODEL.FPN.USE_GN, cfg.MODEL.FPN.USE_RELU
        ),
        top_blocks=fpn_module.LastLevelMaxPool(),
    )
    model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)]))
    model.out_channels = out_channels
    return model


@registry.BACKBONES.register("R-50-FPN-RETINANET")
@registry.BACKBONES.register("R-101-FPN-RETINANET")
def build_resnet_fpn_p3p7_backbone(cfg):
    body = resnet.ResNet(cfg)
    in_channels_stage2 = cfg.MODEL.RESNETS.RES2_OUT_CHANNELS
    out_channels = cfg.MODEL.RESNETS.BACKBONE_OUT_CHANNELS
    in_channels_p6p7 = in_channels_stage2 * 8 if cfg.MODEL.RETINANET.USE_C5 \
        else out_channels
    fpn = fpn_module.FPN(
        in_channels_list=[
            0,
            in_channels_stage2 * 2,
            in_channels_stage2 * 4,
            in_channels_stage2 * 8,
        ],
        out_channels=out_channels,
        conv_block=conv_with_kaiming_uniform(
            cfg.MODEL.FPN.USE_GN, cfg.MODEL.FPN.USE_RELU
        ),
        top_blocks=fpn_module.LastLevelP6P7(in_channels_p6p7, out_channels),
    )
    model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)]))
    model.out_channels = out_channels
    return model
```

而HRNet_MaskRCNN中的hrnet是没有这个属性的。因此解决办法是：搞清楚HRNet_MaskRCNN中的hrnet的out_channels属性在传参时候的异同，进行修改。

```python
@registry.BACKBONES.register("HRNET")
def build_msnet_backbone(cfg):
    body = hrnet.HRNet(cfg)
    model = nn.Sequential(OrderedDict([("body", body)]))
    return model


@registry.BACKBONES.register('HRNET-FPN')  ##我觉得应该叫HRNET-FPN
def build_hrnet_hr_backbone(cfg):
    body = hrnet.HRNet(cfg)
    neck = hrfpn.HRFPN(cfg)
    model = nn.Sequential(OrderedDict([('body', body), ('neck', neck)]))
    return model
```





在maskrcnn的关键点检测方法中引入hrnet中的heatmap，结合hrnet中的lib/dataset/中的coco.py和JointsDataset.py，重写maskrcnn-benchmark中的/maskrcnn_benchmark/data/datasets/coco.py

```python
    def __getitem__(self, idx):
        img, anno = super(COCODataset, self).__getitem__(idx)

        # filter crowd annotations
        # TODO might be better to add an extra field
        anno = [obj for obj in anno if obj["iscrowd"] == 0]

        boxes = [obj["bbox"] for obj in anno]
        boxes = torch.as_tensor(boxes).reshape(-1, 4)  # guard against no boxes
        target = BoxList(boxes, img.size, mode="xywh").convert("xyxy")

        classes = [obj["category_id"] for obj in anno]
        classes = [self.json_category_id_to_contiguous_id[c] for c in classes]
        classes = torch.tensor(classes)
        target.add_field("labels", classes)

        if anno and "segmentation" in anno[0]:
            masks = [obj["segmentation"] for obj in anno]
            masks = SegmentationMask(masks, img.size, mode='poly')
            target.add_field("masks", masks)

        if anno and "keypoints" in anno[0]:
            keypoints = [obj["keypoints"] for obj in anno]
            keypoints = PersonKeypoints(keypoints, img.size)
            target.add_field("keypoints", keypoints)

        target = target.clip_to_image(remove_empty=True)

        if self._transforms is not None:
            img, target = self._transforms(img, target)

        return img, target, idx
```

+ **把上面的target重写好**：



+ 注意，hrnet中dataloader的dataset类的get item是加载人的实例，而maskrcnn训练时get item加载的是图片。
+ 要注意keypoint_head的输出要从[N, K, 3]变换成[N, K, 64, 48]，并重新计算损失函数。原损失函数在modeling/roi_heads/keypoint_head/loss.py中。





训练过程中损失函数的调用：

```python
    for iteration, (images, targets, _) in enumerate(data_loader, start_iter):
        
        if any(len(target) < 1 for target in targets):
            logger.error(f"Iteration={iteration + 1} || Image Ids used for training {_} || targets Length={[len(target) for target in targets]}" )
            continue
        data_time = time.time() - end
        iteration = iteration + 1
        arguments["iteration"] = iteration

        images = images.to(device)
        targets = [target.to(device) for target in targets]

        loss_dict = model(images, targets)

        losses = sum(loss for loss in loss_dict.values())
```

因此，当前的重点是把targets和loss重写好。

以终为始，先看loss。/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py中会求取损失函数并返回：

```python
class ROIKeypointHead(torch.nn.Module):
    def __init__(self, cfg, in_channels):
        super(ROIKeypointHead, self).__init__()
        self.cfg = cfg.clone()
        self.feature_extractor = make_roi_keypoint_feature_extractor(cfg, in_channels)
        self.predictor = make_roi_keypoint_predictor(
            cfg, self.feature_extractor.out_channels)
        self.post_processor = make_roi_keypoint_post_processor(cfg)
        self.loss_evaluator = make_roi_keypoint_loss_evaluator(cfg)

    def forward(self, features, proposals, targets=None):
        """
        Arguments:
            features (list[Tensor]): feature-maps from possibly several levels
            proposals (list[BoxList]): proposal boxes
            targets (list[BoxList], optional): the ground-truth targets.

        Returns:
            x (Tensor): the result of the feature extractor
            proposals (list[BoxList]): during training, the original proposals
                are returned. During testing, the predicted boxlists are returned
                with the `mask` field set
            losses (dict[Tensor]): During training, returns the losses for the
                head. During testing, returns an empty dict.
        """
        if self.training:
            with torch.no_grad():
                proposals = self.loss_evaluator.subsample(proposals, targets)  ##调用的是loss.py中的class KeypointRCNNLossComputation(object):中的subsample

        x = self.feature_extractor(features, proposals)  ##此处得到的是[persom_num, 17, 28, 28]的特征图，此处修改成heatmap的维度
        kp_logits = self.predictor(x)  ##得到关键点的坐标[persom_num, 17, 3]，这一层直接干掉，将上面的heatmap与gt heatmap一起用于计算损失函数

        if not self.training:
            result = self.post_processor(kp_logits, proposals)
            return x, result, {}

        loss_kp = self.loss_evaluator(proposals, kp_logits)

        return x, proposals, dict(loss_kp=loss_kp)
        
        
```

keypoint损失函数计算：/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/loss.py中在计算loss

```python
def make_roi_keypoint_loss_evaluator(cfg):
    matcher = Matcher(
        cfg.MODEL.ROI_HEADS.FG_IOU_THRESHOLD,
        cfg.MODEL.ROI_HEADS.BG_IOU_THRESHOLD,
        allow_low_quality_matches=False,
    )
    fg_bg_sampler = BalancedPositiveNegativeSampler(
        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE, cfg.MODEL.ROI_HEADS.POSITIVE_FRACTION
    )
    resolution = cfg.MODEL.ROI_KEYPOINT_HEAD.RESOLUTION  ##在yaml配置文件中赋值了，为56。
    loss_evaluator = KeypointRCNNLossComputation(matcher, fg_bg_sampler, resolution)
    return loss_evaluator

```

```python
class KeypointRCNNLossComputation(object):
    def __init__(self, proposal_matcher, fg_bg_sampler, discretization_size):
        """
        Arguments:
            proposal_matcher (Matcher)
            fg_bg_sampler (BalancedPositiveNegativeSampler)
            discretization_size (int)
        """
        self.proposal_matcher = proposal_matcher
        self.fg_bg_sampler = fg_bg_sampler
        self.discretization_size = discretization_size

    def __call__(self, proposals, keypoint_logits):
        heatmaps = []
        valid = []
        for proposals_per_image in proposals:
            kp = proposals_per_image.get_field("keypoints")
            heatmaps_per_image, valid_per_image = project_keypoints_to_heatmap(
                kp, proposals_per_image, self.discretization_size
            )
            heatmaps.append(heatmaps_per_image.view(-1))
            valid.append(valid_per_image.view(-1))

        keypoint_targets = cat(heatmaps, dim=0)
        valid = cat(valid, dim=0).to(dtype=torch.bool)
        valid = torch.nonzero(valid).squeeze(1)

        # torch.mean (in binary_cross_entropy_with_logits) does'nt
        # accept empty tensors, so handle it separately
        if keypoint_targets.numel() == 0 or len(valid) == 0:
            return keypoint_logits.sum() * 0

        N, K, H, W = keypoint_logits.shape
        keypoint_logits = keypoint_logits.view(N * K, H * W)

        keypoint_loss = F.cross_entropy(keypoint_logits[valid], keypoint_targets[valid])
        return keypoint_loss
```

```python
def project_keypoints_to_heatmap(keypoints, proposals, discretization_size):
    proposals = proposals.convert("xyxy")
    return keypoints_to_heat_map(
        keypoints.keypoints, proposals.bbox, discretization_size
    )
```

调用了/maskrcnn_benchmark/structures/keypoint.py中的keypoints_to_heat_map：

```python
# TODO make this nicer, this is a direct translation from C2 (but removing the inner loop)
def keypoints_to_heat_map(keypoints, rois, heatmap_size):
    if rois.numel() == 0:
        return rois.new().long(), rois.new().long()
    offset_x = rois[:, 0]
    offset_y = rois[:, 1]
    scale_x = heatmap_size / (rois[:, 2] - rois[:, 0])
    scale_y = heatmap_size / (rois[:, 3] - rois[:, 1])

    offset_x = offset_x[:, None]
    offset_y = offset_y[:, None]
    scale_x = scale_x[:, None]
    scale_y = scale_y[:, None]

    x = keypoints[..., 0]
    y = keypoints[..., 1]

    x_boundary_inds = x == rois[:, 2][:, None]
    y_boundary_inds = y == rois[:, 3][:, None]

    x = (x - offset_x) * scale_x
    x = x.floor().long()
    y = (y - offset_y) * scale_y
    y = y.floor().long()
    
    x[x_boundary_inds] = heatmap_size - 1
    y[y_boundary_inds] = heatmap_size - 1

    valid_loc = (x >= 0) & (y >= 0) & (x < heatmap_size) & (y < heatmap_size)
    vis = keypoints[..., 2] > 0
    valid = (valid_loc & vis).long()

    lin_ind = y * heatmap_size + x
    heatmaps = lin_ind * valid

    ##heatmaps的维度为[person_num, 17, 3], valid的维度为[person_num, 17]
    return heatmaps, valid
```





keypoint_head中预测关键点的地方：

```python
@registry.ROI_KEYPOINT_PREDICTOR.register("KeypointRCNNPredictor")
class KeypointRCNNPredictor(nn.Module):
    def __init__(self, cfg, in_channels):
        super(KeypointRCNNPredictor, self).__init__()
        input_features = in_channels
        num_keypoints = cfg.MODEL.ROI_KEYPOINT_HEAD.NUM_CLASSES
        deconv_kernel = 4
        self.kps_score_lowres = layers.ConvTranspose2d(
            input_features,
            num_keypoints,
            deconv_kernel,
            stride=2,
            padding=deconv_kernel // 2 - 1,
        )
        nn.init.kaiming_normal_(
            self.kps_score_lowres.weight, mode="fan_out", nonlinearity="relu"
        )
        nn.init.constant_(self.kps_score_lowres.bias, 0)
        self.up_scale = 2
        self.out_channels = num_keypoints

    def forward(self, x):
        x = self.kps_score_lowres(x)
        x = layers.interpolate(
            x, scale_factor=self.up_scale, mode="bilinear", align_corners=False
        )
        return x


def make_roi_keypoint_predictor(cfg, in_channels):
    func = registry.ROI_KEYPOINT_PREDICTOR[cfg.MODEL.ROI_KEYPOINT_HEAD.PREDICTOR]
    return func(cfg, in_channels)
```





/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/roi_keypoint_feature_extractors.py

```python
from torch import nn
from torch.nn import functional as F

from maskrcnn_benchmark.modeling import registry
from maskrcnn_benchmark.modeling.poolers import Pooler

from maskrcnn_benchmark.layers import Conv2d


@registry.ROI_KEYPOINT_FEATURE_EXTRACTORS.register("KeypointRCNNFeatureExtractor")
class KeypointRCNNFeatureExtractor(nn.Module):
    def __init__(self, cfg, in_channels):
        super(KeypointRCNNFeatureExtractor, self).__init__()

        resolution = cfg.MODEL.ROI_KEYPOINT_HEAD.POOLER_RESOLUTION
        scales = cfg.MODEL.ROI_KEYPOINT_HEAD.POOLER_SCALES
        sampling_ratio = cfg.MODEL.ROI_KEYPOINT_HEAD.POOLER_SAMPLING_RATIO
        pooler = Pooler(
            output_size=(resolution, resolution),
            scales=scales,
            sampling_ratio=sampling_ratio,
        )
        self.pooler = pooler

        input_features = in_channels
        layers = cfg.MODEL.ROI_KEYPOINT_HEAD.CONV_LAYERS  ##在maskrcnn_benchmark/config/defaults.py中
        next_feature = input_features
        self.blocks = []
        for layer_idx, layer_features in enumerate(layers, 1):
            layer_name = "conv_fcn{}".format(layer_idx)
            module = Conv2d(next_feature, layer_features, 3, stride=1, padding=1)
            nn.init.kaiming_normal_(module.weight, mode="fan_out", nonlinearity="relu")
            nn.init.constant_(module.bias, 0)
            self.add_module(layer_name, module)
            next_feature = layer_features
            self.blocks.append(layer_name)
        self.out_channels = layer_features

    def forward(self, x, proposals):
        x = self.pooler(x, proposals)
        for layer_name in self.blocks:
            x = F.relu(getattr(self, layer_name)(x))
        return x


def make_roi_keypoint_feature_extractor(cfg, in_channels):
    func = registry.ROI_KEYPOINT_FEATURE_EXTRACTORS[
        cfg.MODEL.ROI_KEYPOINT_HEAD.FEATURE_EXTRACTOR
    ]
    return func(cfg, in_channels)

```

在maskrcnn_benchmark/config/defaults.py中

```python
_C.MODEL.ROI_KEYPOINT_HEAD = CN()
_C.MODEL.ROI_KEYPOINT_HEAD.FEATURE_EXTRACTOR = "KeypointRCNNFeatureExtractor"
_C.MODEL.ROI_KEYPOINT_HEAD.PREDICTOR = "KeypointRCNNPredictor"
_C.MODEL.ROI_KEYPOINT_HEAD.POOLER_RESOLUTION = 14
_C.MODEL.ROI_KEYPOINT_HEAD.POOLER_SAMPLING_RATIO = 0
_C.MODEL.ROI_KEYPOINT_HEAD.POOLER_SCALES = (1.0 / 16,)
_C.MODEL.ROI_KEYPOINT_HEAD.MLP_HEAD_DIM = 1024
_C.MODEL.ROI_KEYPOINT_HEAD.CONV_LAYERS = tuple(512 for _ in range(8))
_C.MODEL.ROI_KEYPOINT_HEAD.RESOLUTION = 14
_C.MODEL.ROI_KEYPOINT_HEAD.NUM_CLASSES = 17
_C.MODEL.ROI_KEYPOINT_HEAD.SHARE_BOX_FEATURE_EXTRACTOR = True
```



20210202

+ 换成heatmap的做法是把/maskrcnn_benchmark/structures/keypoint.py中的keypoints_to_heat_map重写，然后把/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/loss.py中计算loss的`class KeypointRCNNLossComputation(object):`中的`def __call__(self, proposals, keypoint_logits):`中的`keypoint_loss = F.cross_entropy(keypoint_logits[valid], keypoint_targets[valid])`换掉：

```python
keypoint_loss = torch.mean(torch.square(keypoint_logits[valid] - keypoint_targets[valid])) * 40
```



+ 













20210201训练完模型后，inference报错：

```txt
021-02-01 23:54:39,446 maskrcnn_benchmark.inference INFO: Start evaluation on keypoints_coco_2017_val dataset(5000 images).
/opt/Software/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
  0%|          | 0/626 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "tools/train_net.py", line 205, in <module>
    main()
  File "tools/train_net.py", line 201, in main
    run_test(cfg, model, args.distributed)
  File "tools/train_net.py", line 132, in run_test
    output_folder=output_folder,
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/engine/inference.py", line 84, in inference
    predictions = compute_on_dataset(model, data_loader, device, bbox_aug, inference_timer)
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/engine/inference.py", line 29, in compute_on_dataset
    output = model(images.to(device))
  File "/opt/Software/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/Software/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/apex-0.1-py3.6.egg/apex/amp/_initialize.py", line 197, in new_fwd
    **applier(kwargs, input_caster))
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py", line 56, in forward
    x, result, detector_losses = self.roi_heads(features, proposals, targets)
  File "/opt/Software/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/modeling/roi_heads/roi_heads.py", line 61, in forward
    x, detections, loss_keypoint = self.keypoint(keypoint_features, detections, targets)
  File "/opt/Software/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/keypoint_head.py", line 42, in forward
    result = self.post_processor(kp_logits, proposals)
  File "/opt/Software/miniconda3/envs/maskrcnn/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/inference.py", line 15, in forward
    mask_prob, scores = self.keypointer(x, boxes)
  File "/opt/SRC/projects/keypoint_detection/maskrcnn-benchmark/maskrcnn_benchmark/modeling/roi_heads/keypoint_head/inference.py", line 114, in __call__
    assert len(boxes) == 1
AssertionError
```

自己运行test_net.py后，得到如下结果：backbone换成hrnet后效果比之前的resnet好一些。

```
Evaluate annotation type *bbox*
DONE (t=29.05s).
Accumulating evaluation results...
DONE (t=2.55s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.284
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.585
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.181
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.370
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.119
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.304
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.516
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.551
Loading and preparing results...
DONE (t=11.84s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *keypoints*
DONE (t=21.38s).
Accumulating evaluation results...
DONE (t=0.68s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.685
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.437
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.604
 Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.832
 Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.632
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.542
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.691
2021-02-02 09:22:20,406 maskrcnn_benchmark.inference INFO: 
Task: bbox
AP, AP50, AP75, APs, APm, APl
0.2837, 0.5847, 0.2347, 0.1808, 0.3746, 0.3701
Task: keypoints
AP, AP50, AP75, APm, APl
0.4657, 0.6848, 0.4952, 0.4373, 0.5274

```







#### TypeError: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.

解决办法是先转换到cpu上，然后转换成list，再转换成np矩阵：

```python
        joints_3d =np.array(keypoints[k].cpu().tolist())  ##17代表关键点个数，3代表(x, y, v)，v为{0:不存在, 1:存在但不可见, 2:存在且可见}
        x1, y1, x2, y2 = list(map(int, np.array(rois[k].cpu().tolist())))
```

然后再转换成CUDA Tensor：

```python
heatmaps = torch.from_numpy(np.array(heatmaps)).cuda()
```



















maskrcnn中nms换成soft_nms